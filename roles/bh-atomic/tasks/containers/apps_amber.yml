
# 389 DS Ldap
- name: Create internal ldap network
  become: true
  docker_network:
    name: ldap_net
    ipam_config:
      - gateway: 172.16.0.1
        iprange: 172.16.0.64/26
        subnet: 172.16.0.0/24
  tags:
    - docker
    - 389ds

- name: Create 389ds volume
  become: true
  docker_volume:
    name: 389ds_data
  tags:
    - docker
    - 389ds

- name: Create 389ds container
  become: true
  docker_container:
    name: 389ds
    image: 389ds/dirsrv:latest
    shm_size: 256M
    purge_networks: yes
    networks:
      - name: ldap_net
    # user: 1389:1389
    volumes:
      - "389ds_data:/data"
    ports:
      - "3389:3389"
      - "3636:3636"
    restart_policy: always
    pull: yes
    log_driver: journald
  tags:
    - docker
    - 389ds


- name: Create docker volume for nextcloud_db
  become: true
  docker_volume:
    name: nextcloud_db
  tags:
    - docker
    - nextcloud

- name: Create docker volume for nextcloud
  become: true
  docker_volume:
    name: nextcloud
  tags:
    - docker
    - nextcloud

# docker network create test-net
- name: Create private DB network
  become: true
  docker_network:
    name: nextcloud_net
    ipam_config:
      - gateway: 172.16.1.1
        iprange: 172.16.1.64/26
        subnet: 172.16.1.0/24
  tags:
    - docker
    - nextcloud

# docker run -v pgdata:/var/lib/postgresql/data  --name pgtest --network test-net postgres:11
- name: Create a pgsql instance for nextcloud
  become: true
  docker_container:
    name: nextcloud_db
    image: postgres:11
    volumes:
      - "nextcloud_db:/var/lib/postgresql/data"
    purge_networks: yes
    networks:
      - name: nextcloud_net
    restart_policy: always
    pull: yes
    log_driver: journald
  tags:
    - docker
    - nextcloud

# docker run --network test-net -p 8080:80 -v nextcloud:/var/www/html nextcloud:latest
#
# docker exec -i -t -u www-data nextcloud php occ upgrade
# docker exec -i -t -u www-data nextcloud php occ maintenance:mode --on
- name: Create nextcloud
  become: true
  docker_container:
    name: nextcloud
    image: nextcloud:18
    volumes:
      - "nextcloud:/var/www/html"
    purge_networks: yes
    networks:
      - name: nextcloud_net
      - name: ldap_net
    restart_policy: always
    pull: yes
    log_driver: journald
  tags:
    - docker
    - nextcloud

- name: Create docker volume for haproxy_certs_le
  become: true
  docker_volume:
    name: haproxy_certs_le
  tags:
    - docker
    - haproxy

- name: Create docker volume for haproxy_certs_cb
  become: true
  docker_volume:
    name: haproxy_certs_cb
  tags:
    - docker
    - haproxy

- name: Create nextcloud-haproxy
  become: true
  docker_container:
    name: haproxy
    image: firstyear/haproxy-linode-dns:latest
    volumes:
      - "haproxy_certs_le:/etc/letsencrypt"
      - "haproxy_certs_cb:/etc/certbot"
    purge_networks: yes
    networks:
      - name: nextcloud_net
    restart_policy: always
    env:
      HAPROXY_TARGET: nextcloud
      HAPROXY_HOSTNAME: nextcloud.blackhats.net.au
      HAPROXY_LINODE_KEY: "{{ haproxy_linode_key }}"
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"
    # Apparently this pulls the latest image always?
    pull: yes
    log_driver: journald
  tags:
    - docker
    - haproxy
    - nextcloud

# - name: Create docker volume for samba ad-dc
#   become: true
#   docker_volume:
#     name: samba_rwdc
#   tags:
#     - docker
#     - sambadc
# 
# # Make sure the container exists with restart-always
# - name: Create samba_rwdc container
#   become: true
#   docker_container:
#     name: samba_rwdc
#     image: registry.blackhats.net.au/samba_rwdc:latest
#     volumes:
#       - "samba_rwdc:/var/lib/samba"
#     ports:
#       - "389:389"
#       - "636:636"
#     restart_policy: always
#     pull: yes
#   tags:
#     - docker
#     - sambadc
# 

# SAMBA
# So it's not docker, but this is the config and avahi setup.

- name: Ensure timemachine user
  become: yes
  user: name=timemachine group=users uid=1001
  tags:
    - docker
    - samba

- name: Ensure scanner user
  become: yes
  user: name=scanner group=users uid=1002
  tags:
    - docker
    - samba

- name: Deploy samba config
  become: yes
  template: src=samba/smb.conf dest=/etc/samba/smb.conf owner=root group=root mode=0600
  tags:
    - docker
    - samba

- name: Deploy rsyncd config
  become: yes
  template: src=samba/rsyncd.conf dest=/etc/rsyncd.conf owner=root group=root mode=0644
  tags:
    - docker
    - samba

# - name: Deploy timemachine quota
#   become: yes
#   template: src=samba/com.apple.TimeMachine.quote.plist dest=/var/data/backup/timemachine/.com.apple.TimeMachine.quote.plist owner=timemachine group=timemachine mode=0600

- name: Ensure samba active
  become: yes
  service: name=smb enabled=yes
  tags:
    - docker
    - samba

- name: Ensure rsyncd active
  become: yes
  service: name=rsyncd enabled=yes
  tags:
    - docker
    - samba

# KANIDM setup
- name: Create docker volume for kanidmd
  become: true
  docker_volume:
    name: kanidmd
  tags:
    - docker
    - kanidm

- name: Create private kanidm network
  become: true
  docker_network:
    name: kanidm_net
    ipam_config:
      - gateway: 172.16.2.1
        iprange: 172.16.2.64/26
        subnet: 172.16.2.0/24
  tags:
    - docker
    - kanidm

- name: Create kanidmd
  become: true
  docker_container:
    name: kanidmd
    image: kanidm/server:latest
    user: 1400:1400
    command: /sbin/kanidmd server -D /data/kanidm.db --bindaddr 0.0.0.0:8080
    volumes:
      - "kanidmd:/data"
    purge_networks: yes
    exposed_ports:
      - "80"
    networks:
      - name: kanidm_net
        ipv4_address: 172.16.2.120
    restart_policy: always
    env:
      RUST_BACKTRACE: full
    # Apparently this pulls the latest image always?
    pull: yes
    log_driver: journald
  tags:
    - docker
    - kanidm

- name: Create docker volume for haproxy_certs_le
  become: true
  docker_volume:
    name: kanidm_haproxy_certs_le
  tags:
    - docker
    - haproxy
    - kanidm

- name: Create docker volume for haproxy_certs_cb
  become: true
  docker_volume:
    name: kanidm_haproxy_certs_cb
  tags:
    - docker
    - haproxy
    - kanidm

- name: Create kanidm-haproxy
  become: true
  docker_container:
    name: kanidm-haproxy
    image: firstyear/haproxy-linode-dns:latest
    volumes:
      - "kanidm_haproxy_certs_le:/etc/letsencrypt"
      - "kanidm_haproxy_certs_cb:/etc/certbot"
    purge_networks: yes
    networks:
      - name: kanidm_net
    restart_policy: always
    env:
      HAPROXY_TARGET: kanidmd
      HAPROXY_TARGET_PORT: "8080"
      HAPROXY_HOSTNAME: idm.blackhats.net.au
      HAPROXY_LINODE_KEY: "{{ haproxy_linode_key }}"
    ports:
      - "8000:80"
      - "8443:443"
      - "8081:8080"
    # Apparently this pulls the latest image always?
    pull: yes
    log_driver: journald
  tags:
    - docker
    - haproxy
    - kanidm


