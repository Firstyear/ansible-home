- name: Create uv1-uv10network (mgmt)
  become: true
  docker_network:
    name: dk_v10_mgmt
    enable_ipv6: yes
    driver: macvlan
    ipam_config:
      - subnet: "172.24.10.0/24"
        iprange: "172.24.10.128/28"
        gateway: "172.24.10.1"
      - subnet: "2001:44b8:2155:2c10::/64"
        iprange: "2001:44b8:2155:2c10::1000/116"
        gateway: "2001:44b8:2155:2c10::1"
    driver_options:
      parent: "bond0.1"
      macvlan_mode: "bridge"
  tags:
    - docker

- name: Create vlan11 (servers)
  become: true
  docker_network:
    name: dk_v11_srvs
    enable_ipv6: yes
    driver: macvlan
    ipam_config:
      - subnet: "172.24.11.0/24"
        iprange: "172.24.11.128/28"
        gateway: "172.24.11.1"
      - subnet: "2001:44b8:2155:2c11::/64"
        iprange: "2001:44b8:2155:2c11::1000/116"
        gateway: "2001:44b8:2155:2c11::1"
    driver_options:
      parent: "bond0.11"
      macvlan_mode: "bridge"
  tags:
    - docker

- name: Create vlan16 (dns + nat64)
  become: true
  docker_network:
    name: dk_v16_dns
    enable_ipv6: yes
    driver: macvlan
    ipam_config:
      - subnet: "172.24.16.0/24"
        iprange: "172.24.16.128/28"
        gateway: "172.24.16.1"
      - subnet: "2001:44b8:2155:2c16::/64"
        iprange: "2001:44b8:2155:2c16::1000/116"
        gateway: "2001:44b8:2155:2c16::1"
    driver_options:
      parent: "bond0.16"
      macvlan_mode: "bridge"
  tags:
    - docker

- name: Create vlan18 (internet of shit)
  become: true
  docker_network:
    name: dk_v18_ios
    enable_ipv6: yes
    driver: macvlan
    ipam_config:
      - subnet: "172.24.18.0/24"
        iprange: "172.24.18.128/28"
        gateway: "172.24.18.1"
      - subnet: "2001:44b8:2155:2c18::/64"
        iprange: "2001:44b8:2155:2c18::1000/116"
        gateway: "2001:44b8:2155:2c18::1"
    driver_options:
      parent: "bond0.18"
      macvlan_mode: "bridge"
  tags:
    - docker

## NAT64 + DNS64

- name: Create tayga container
  become: true
  docker_container:
    name: tayga
    image: danehans/tayga:latest
    restart_policy: unless-stopped
    pull: yes
    privileged: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v16_dns
        ipv4_address: 172.24.16.129
        ipv6_address: 2001:44b8:2155:2c16::1001
    sysctls:
      net.ipv6.conf.all.disable_ipv6: 0
      net.ipv6.conf.all.forwarding: 1
    env:
      TAYGA_CONF_DATA_DIR: /var/db/tayga
      TAYGA_CONF_DIR: /usr/local/etc
      TAYGA_CONF_IPV4_ADDR: 172.24.16.129
      TAYGA_IPV6_ADDR: 2001:44b8:2155:2c16::1001
      TAYGA_CONF_PREFIX: 2001:44b8:2155:2c64::/96
      TAYGA_CONF_DYNAMIC_POOL: 172.24.64.0/24
  tags:
    - docker
    - tayga
    - nat64

- name: Create dns64 data volume
  become: true
  docker_volume:
    name: dns64_data
  tags:
    - docker
    - dns64
    - nat64

- name: dns64 config folder
  become: true
  file:
    path: /etc/dns64
    state: directory
    mode: '0750'
  tags:
    - docker
    - dns64
    - nat64

- name: dns64 config
  become: true
  template: src=dns64/named.conf dest=/etc/dns64/named.conf owner=root group=root mode=0644
  with_items:
    - named.conf
  tags:
    - docker
    - dns64
    - nat64

- name: dns64 config
  become: true
  template: src=../../do_not_commit_templates/dns64/{{ item }} dest=/etc/dns64/{{ item }} owner=root group=root mode=0644
  with_items:
    - rndc.key
    - rndc.conf
  tags:
    - docker
    - dns64
    - nat64

- name: Create DNS64 server
  become: true
  docker_container:
    name: dns64
    image: firstyear/dns64:latest
    restart_policy: unless-stopped
    pull: yes
    # user: 1007:1007
    memory: 512M
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v16_dns
        ipv4_address: 172.24.16.130
        ipv6_address: 2001:44b8:2155:2c16::1002
    volumes:
      - "dns64_data:/var/lib/named/slave/"
      - "/etc/dns64/named.conf:/etc/named.conf"
      - "/etc/dns64/rndc.key:/etc/rndc.key"
      - "/etc/dns64/rndc.conf:/etc/rndc.conf"
    sysctls:
      net.ipv6.conf.all.accept_ra: 0
      net.ipv6.conf.default.accept_ra: 0
      net.ipv6.conf.eth0.accept_ra: 0
      net.ipv6.conf.all.use_tempaddr: 0
      net.ipv6.conf.default.use_tempaddr: 0
      net.ipv6.conf.eth0.use_tempaddr: 0
  tags:
    - docker
    - dns64
    - nat64

## MICD

- name: zfs tank/comp/micd
  become: yes
  zfs:
    name: tank/comp/micd
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/comp/micd
      recordsize: 4K
      quota: 20G
  tags:
    - zfs
    - docker
    - micd

- name: Create micd controller
  become: true
  docker_container:
    name: micd
    image: firstyear/micd:latest
    restart_policy: unless-stopped
    pull: yes
    user: 1006:1006
    memory: 400M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v18_ios
        ipv4_address: 172.24.18.140
        ipv6_address: 2001:44b8:2155:2c18::1001
      - name: dk_v10_mgmt
        ipv4_address: 172.24.10.130
        ipv6_address: 2001:44b8:2155:2c10::1002
    volumes:
      - "/mnt/comp/micd:/data"
    env:
      RUST_LOG: "actix=info,micd=info,mic=info"
  tags:
    - docker
    - micd


## LIFX

- name: Create lifx controller
  become: true
  docker_container:
    name: lifx
    image: firstyear/lifx:latest
    restart_policy: unless-stopped
    pull: yes
    user: 1005:1005
    memory: 400M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v18_ios
        ipv4_address: 172.24.18.141
        ipv6_address: 2001:44b8:2155:2c18::1002
      - name: dk_v10_mgmt
        ipv4_address: 172.24.10.131
        ipv6_address: 2001:44b8:2155:2c10::1003
    env:
      RUST_LOG: "actix=debug,lifx=info"
  tags:
    - docker
    - lifx

### Kanidm

- name: zfs tank/comp/kanidm
  become: yes
  zfs:
    name: tank/comp/kanidm
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/comp/kanidm
      recordsize: 64K
      quota: 40G
      copies: 2
      primarycache: metadata
  tags:
    - zfs
    - docker
    - kanidm

- name: Secure kanidm dir
  become: yes
  file:
    path: /mnt/comp/kanidm
    owner: root
    group: '1400'
    mode: '0770'
  tags:
    - zfs
    - docker
    - kanidm

- name: Create private kanidm network
  become: true
  docker_network:
    name: kanidm_net
    ipam_config:
      - gateway: 172.16.2.1
        iprange: 172.16.2.64/26
        subnet: 172.16.2.0/24
  tags:
    - docker
    - kanidm

- name: Deploy kanidm server.toml
  become: yes
  template: src=base/kanidm/server.toml dest=/mnt/comp/kanidm/server.toml owner=root group='1400' mode=0440
  tags:
    - docker
    - kanidm

- name: Create kanidmd
  become: true
  docker_container:
    name: kanidmd
    image: kanidm/server:devel
    restart_policy: unless-stopped
    pull: yes
    user: 1400:1400
    memory: 4096M
    cpu_period: 100000
    cpu_quota: 400000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: kanidm_net
        ipv4_address: 172.16.2.120
    volumes:
      - "/mnt/comp/kanidm:/data"
    env:
      RUST_BACKTRACE: full
  tags:
    - docker
    - kanidm

- name: Create docker volume for haproxy_certs_le
  become: true
  docker_volume:
    name: kanidm_haproxy_certs_le
  tags:
    - docker
    - haproxy
    - kanidm

- name: Create docker volume for haproxy_certs_cb
  become: true
  docker_volume:
    name: kanidm_haproxy_certs_cb
  tags:
    - docker
    - haproxy
    - kanidm

- name: Create kanidm-haproxy
  become: true
  docker_container:
    name: kanidm-haproxy
    image: firstyear/haproxy-linode-dns:latest
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: kanidm_net
      - name: dk_v11_srvs
        ipv4_address: 172.24.11.129
        ipv6_address: 2001:44b8:2155:2c11::1001
    volumes:
      - "kanidm_haproxy_certs_le:/etc/letsencrypt"
      - "kanidm_haproxy_certs_cb:/etc/certbot"
    env:
      HAPROXY_TARGET: kanidmd
      HAPROXY_TARGET_PORT: "8080"
      HAPROXY_HOSTNAME: idm.blackhats.net.au
      HAPROXY_LINODE_KEY: "{{ haproxy_linode_key }}"
      HAPROXY_RAW_TARGET_PORT: "3389"
      HAPROXY_RAW_LISTEN_PORT: "636"
  tags:
    - docker
    - haproxy
    - kanidm
  # ports:
  #   - "8000:80"
  #   - "8443:443"
  #   - "8081:8080"
  #   - "636:636"

## Nextcloud
- name: zfs tank/comp/nexcloud
  become: yes
  zfs:
    name: tank/comp/nextcloud
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/comp/nextcloud
      quota: 1200G
  tags:
    - docker
    - zfs
    - nextcloud

- name: zfs tank/nexcloud_db
  become: yes
  zfs:
    name: tank/nextcloud_db
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/nextcloud_db
      recordsize: 8K
      logbias: latency
      primarycache: metadata
      quota: 40G
  tags:
    - docker
    - zfs
    - nextcloud

- name: Create private DB network
  become: true
  docker_network:
    name: nextcloud_net
    ipam_config:
      - gateway: 172.16.1.1
        iprange: 172.16.1.64/26
        subnet: 172.16.1.0/24
  tags:
    - docker
    - nextcloud

- name: Create a pgsql instance for nextcloud
  become: true
  docker_container:
    name: nextcloud_db
    image: postgres:11
    restart_policy: unless-stopped
    pull: yes
    # user
    memory: 2048M
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: nextcloud_net
    volumes:
      - "/mnt/nextcloud_db:/var/lib/postgresql/data"
    shm_size: 256M
  tags:
    - docker
    - nextcloud

# docker run --network test-net -p 8080:80 -v nextcloud:/var/www/html nextcloud:latest
#
# docker exec -i -t -u www-data nextcloud php occ upgrade
# docker exec -i -t -u www-data nextcloud php occ maintenance:mode --on

- name: Create nextcloud
  become: true
  docker_container:
    name: nextcloud
    image: nextcloud:18
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: nextcloud_net
    volumes:
      - "/mnt/comp/nextcloud:/var/www/html"
  tags:
    - docker
    - nextcloud

- name: Create docker volume for haproxy_certs_le
  become: true
  docker_volume:
    name: haproxy_certs_le
  tags:
    - docker
    - haproxy
    - nextcloud

- name: Create docker volume for haproxy_certs_cb
  become: true
  docker_volume:
    name: haproxy_certs_cb
  tags:
    - docker
    - haproxy
    - nextcloud

- name: Create nextcloud-haproxy
  become: true
  docker_container:
    name: nextcloud-haproxy
    image: firstyear/haproxy-linode-dns:latest
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: nextcloud_net
      - name: dk_v11_srvs
        ipv4_address: 172.24.11.130
        ipv6_address: 2001:44b8:2155:2c11::1002
    volumes:
      - "haproxy_certs_le:/etc/letsencrypt"
      - "haproxy_certs_cb:/etc/certbot"
    env:
      HAPROXY_TARGET: nextcloud
      HAPROXY_HOSTNAME: nextcloud.blackhats.net.au
      HAPROXY_LINODE_KEY: "{{ haproxy_linode_key }}"
  tags:
    - docker
    - haproxy
    - nextcloud

## SAMBA

- name: Create samba config volume
  become: true
  docker_volume:
    name: samba_config
  tags:
    - docker
    - samba

- name: Deploy samba config
  become: true
  template:
    src: "samba/smb.conf"
    dest: "/var/lib/docker/volumes/samba_config/_data/smb.conf"
    owner: root
    group: root
    mode: '0600'
  tags:
    - docker
    - samba

- name: zfs tank/samba_db
  become: yes
  zfs:
    name: tank/samba_db
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/samba_db
      recordsize: 4K
      quota: 8G
  tags:
    - docker
    - samba
    - zfs

- name: Create samba container
  become: true
  docker_container:
    name: samba
    image: firstyear/samba:latest
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v11_srvs
        ipv4_address: 172.24.11.131
        ipv6_address: 2001:44b8:2155:2c11::1003
    volumes:
      - "/etc/nsswitch.conf:/etc/nsswitch.conf:ro"
      - "samba_config:/etc/samba:ro"
      - "/mnt/samba_db:/var/lib/samba"
      - "/mnt/comp/home:/home"
      - "/mnt/comp/pub:/var/data/pub"
      - "/mnt/comp/backups:/var/data/backup"
      - "/run/kanidm-unixd:/run/kanidm-unixd"
  tags:
    - docker
    - samba

## RSYNCD

- name: Deploy rsyncd config
  become: yes
  template: src=samba/rsyncd.conf dest=/etc/rsyncd.conf owner=root group=root mode=0644
  tags:
    - docker
    - rsyncd

- name: Create rsyncd container
  become: true
  docker_container:
    name: rsyncd
    image: firstyear/rsyncd:latest
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v11_srvs
        ipv4_address: 172.24.11.132
        ipv6_address: 2001:44b8:2155:2c11::1004
    volumes:
      - "/etc/nsswitch.conf:/etc/nsswitch.conf:ro"
      - "/etc/rsyncd.conf:/etc/rsyncd.conf:ro"
      - "/mnt/comp/pub:/var/data/pub:ro"
      - "/run/kanidm-unixd:/run/kanidm-unixd"
  tags:
    - docker
    - rsyncd

## Radiusd

- name: Create kanidm radiusd LE volume (bne1)
  become: true
  docker_volume:
    name: kanidm_radiusd_bne1_le
  tags:
    - docker
    - radius
    - radiusbne1
    - kanidm

- name: Create kanidm radiusd volume (bne1)
  become: true
  docker_volume:
    name: kanidm_radiusd_bne1
  tags:
    - docker
    - radius
    - radiusbne1
    - kanidm

- name: Create kanidm radiusd lets encrypt (bne1)
  become: true
  docker_container:
    name: radiusd_le_bne1
    image: firstyear/le-linode-dns:devel
    restart_policy: unless-stopped
    pull: yes
    memory: 1024MB
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: bridge
    volumes:
      - "kanidm_radiusd_bne1_le:/etc/letsencrypt"
      - "/etc/resolv.conf:/etc/resolv.conf"
    env:
      DEBUG: "true"
      LE_LINODE_KEY: "{{ haproxy_linode_key }}"
      LE_HOSTNAME: "radius.bne1.net.blackhats.net.au"
  tags:
    - docker
    - kanidm
    - radius
    - radiusbne1

- name: Configure kanidm radiusd (bne1)
  become: true
  template:
    src: "../../do_not_commit_templates/radiusd_bne1/{{ item }}"
    dest: "/var/lib/docker/volumes/kanidm_radiusd_bne1/_data/{{ item }}"
    owner: root
    group: root
    mode: '0644'
  with_items:
    - config.ini
    - dh
    - kanidm_ca.pem
  tags:
    - docker
    - radius
    - radiusbne1
    - kanidm

- name: Create kanidm radiusd controller (bne1)
  become: true
  docker_container:
    name: radiusd_bne1
    image: kanidm/radius:devel
    restart_policy: unless-stopped
    pull: yes
    # user: 1008:1008
    memory: 2048M
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v10_mgmt
        ipv4_address: 172.24.10.132
        ipv6_address: 2001:44b8:2155:2c10::1004
    volumes:
      - "kanidm_radiusd_bne1:/data"
      - "kanidm_radiusd_bne1_le:/le"
      - "/etc/resolv.conf:/etc/resolv.conf"
    env:
      DEBUG: "true"
  tags:
    - docker
    - kanidm
    - radius
    - radiusbne1

- name: Create kanidm radiusd LE volume (bne2)
  become: true
  docker_volume:
    name: kanidm_radiusd_bne2_le
  tags:
    - docker
    - radius
    - radiusbne2
    - kanidm

- name: Create kanidm radiusd volume (bne2)
  become: true
  docker_volume:
    name: kanidm_radiusd_bne2
  tags:
    - docker
    - radius
    - radiusbne2
    - kanidm

- name: Configure kanidm radiusd (bne2)
  become: true
  template:
    src: "../../do_not_commit_templates/radiusd_bne2/{{ item }}"
    dest: "/var/lib/docker/volumes/kanidm_radiusd_bne2/_data/{{ item }}"
    owner: root
    group: root
    mode: '0644'
  with_items:
    - config.ini
    - dh
    - kanidm_ca.pem
  tags:
    - docker
    - radius
    - radiusbne2
    - kanidm

- name: Create kanidm radiusd lets encrypt (bne2)
  become: true
  docker_container:
    name: radiusd_le_bne2
    image: firstyear/le-linode-dns:devel
    restart_policy: unless-stopped
    pull: yes
    memory: 1024MB
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: bridge
    volumes:
      - "kanidm_radiusd_bne2_le:/etc/letsencrypt"
      - "/etc/resolv.conf:/etc/resolv.conf"
    env:
      DEBUG: "true"
      LE_LINODE_KEY: "{{ haproxy_linode_key }}"
      LE_HOSTNAME: "radius.bne2.net.blackhats.net.au"
  tags:
    - docker
    - kanidm
    - radius
    - radiusbne2

- name: Create kanidm radiusd controller (bne2)
  become: true
  docker_container:
    name: radiusd_bne2
    image: kanidm/radius:latest
    restart_policy: unless-stopped
    pull: yes
    # user: 1008:1008
    memory: 2048M
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v10_mgmt
        ipv4_address: 172.24.10.133
        ipv6_address: 2001:44b8:2155:2c10::1005
    volumes:
      - "kanidm_radiusd_bne2:/data"
      - "kanidm_radiusd_bne2_le:/le"
      - "/etc/resolv.conf:/etc/resolv.conf"
    env:
      DEBUG: "true"
  tags:
    - docker
    - kanidm
    - radius
    - radiusbne2

## UNIFI
# check: python -m json.tool config.gateway.json
# show: mca-ctrl -t dump-cfg
# sudo /opt/vyatta/sbin/dhcpv6-pd-client.pl --ifname pppoe0 --renew
# 
# can ssh to aps with ubnt:ubnt and run;
# mca-cli
# set-inform http://<host_ip>:8080/inform
# set-inform http://172.24.10.134:8080/inform
#
# https://help.ui.com/hc/en-us/articles/205202560-EdgeRouter-Add-Debian-Packages-to-EdgeOS
#
# set system package repository wheezy components 'main contrib non-free'
# set system package repository wheezy distribution wheezy
# set system package repository wheezy url http://archive.debian.org/debian
#
# set system package repository wheezy-backports components 'main contrib non-free'
# set system package repository wheezy-backports distribution wheezy-backports
# set system package repository wheezy-backports url http://archive.debian.org/debian
#
# commit ; save
# sudo apt-get update
# sudo apt-cache search dnsutils
# sudo apt-get install dnsutils
# 

- name: zfs tank/unifi_data
  become: yes
  zfs:
    name: tank/unifi_data
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/unifi_data
      recordsize: 4K
      quota: 80G
  tags:
    - docker
    - unifi
    - zfs

- name: Deploy sites config.gateway.json
  become: yes
  template: src=unifi/{{ item }} dest=/mnt/unifi_data/{{ item }} owner=root group=root mode=0600
  with_items:
    - sites/default/config.gateway.json
    - sites/abvd2n5d/config.gateway.json
  tags:
    - docker
    - unifi
    - unificfg

- name: Create unifi log volume
  become: true
  docker_volume:
    name: unifi_log
  tags:
    - docker
    - unifi

- name: Create unifi controller
  become: true
  docker_container:
    name: unifi
    image: jacobalberty/unifi:stable-5
    restart_policy: unless-stopped
    pull: yes
    memory: 2048M
    cpu_period: 100000
    cpu_quota: 200000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v10_mgmt
        ipv4_address: 172.24.10.134
        ipv6_address: 2001:44b8:2155:2c10::1006
    volumes:
      - "/mnt/unifi_data:/unifi/data"
      - "unifi_log:/unifi/log"
      - "/etc/localtime:/etc/localtime:ro"
    # env:
    #   TZ: "Australia/Brisbane"
  tags:
    - docker
    - unifi

#### Zone Minder

- name: zfs tank/comp/zm_data
  become: yes
  zfs:
    name: tank/comp/zm_data
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/comp/zm_data
      quota: 200G
      primarycache: metadata
  tags:
    - zfs
    - docker
    - zm

- name: zfs tank/zm_db
  become: yes
  zfs:
    name: tank/zm_db
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/zm_db
      recordsize: 16K
      logbias: latency
      primarycache: metadata
      quota: 40G
  tags:
    - zfs
    - docker
    - zm

- name: Create zm volumes
  become: true
  docker_volume:
    name: '{{ item }}'
  with_items:
    - zm_logs
  tags:
    - docker
    - zm

- name: Create private zm network
  become: true
  docker_network:
    name: zm_net
    ipam_config:
      - gateway: 172.16.3.1
        iprange: 172.16.3.64/26
        subnet: 172.16.3.0/24
  tags:
    - docker
    - zm

- name: Create zm container
  become: true
  docker_container:
    name: zm
    image: zoneminderhq/zoneminder:latest-el7
    restart_policy: unless-stopped
    # pull: yes
    memory: 2048M
    cpu_period: 100000
    # Use 2x cpu
    cpu_quota: 400000
    # device_read_bps:
    # device_read_iops:
    # device_write_bps:
    #   - path: 20M
    # device_write_iops:
    purge_networks: yes
    log_driver: journald
    exposed_ports:
      - '80'
      - '443'
    networks:
      - name: zm_net
      # - name: dk_v10_mgmt
      #   ipv4_address: 172.24.10.129
      #   ipv6_address: 2001:44b8:2155:2c10::1001
    shm_size: 1024M
    volumes:
      - "/mnt/comp/zm_data:/var/lib/zoneminder/events"
      - "/mnt/comp/zm_data/zoneminder.conf:/etc/httpd/conf.d/zoneminder.conf"
      - "/mnt/zm_db:/var/lib/mysql"
      - "zm_logs:/var/log/zm"
    env:
      TZ: "Australia/Brisbane"
  tags:
    - docker
    - zm

- name: Create docker volume for zm_haproxy_certs_le
  become: true
  docker_volume:
    name: zm_haproxy_certs_le
  tags:
    - docker
    - haproxy
    - zm

- name: Create docker volume for zm_haproxy_certs_cb
  become: true
  docker_volume:
    name: zm_haproxy_certs_cb
  tags:
    - docker
    - haproxy
    - zm

- name: Create zm-haproxy
  become: true
  docker_container:
    name: zm-haproxy
    image: firstyear/haproxy-linode-dns:latest
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: zm_net
      - name: dk_v10_mgmt
        ipv4_address: 172.24.10.129
        ipv6_address: 2001:44b8:2155:2c10::1001
    volumes:
      - "zm_haproxy_certs_le:/etc/letsencrypt"
      - "zm_haproxy_certs_cb:/etc/certbot"
    env:
      HAPROXY_TARGET: zm
      HAPROXY_HOSTNAME: zm.fy.blackhats.net.au
      HAPROXY_LINODE_KEY: "{{ haproxy_linode_key }}"
  tags:
    - docker
    - haproxy
    - zm

### Avahi

- name: zfs tank/comp/avahi
  become: yes
  zfs:
    name: tank/comp/avahi
    state: present
    extra_zfs_properties:
      mountpoint: /mnt/comp/avahi
      quota: 8G
  tags:
    - docker
    - avahi
    - zfs

# Deploy config here!

- name: Create avahi container
  become: true
  docker_container:
    name: avahi
    image: firstyear/avahi:latest
    restart_policy: unless-stopped
    pull: yes
    memory: 1024M
    cpu_period: 100000
    cpu_quota: 100000
    purge_networks: yes
    log_driver: journald
    networks:
      - name: dk_v11_srvs
        ipv4_address: 172.24.11.133
        ipv6_address: 2001:44b8:2155:2c11::1005
    volumes:
      - "/etc/nsswitch.conf:/etc/nsswitch.conf:ro"
      - "/mnt/comp/avahi/avahi-daemon.conf:/etc/avahi/avahi-daemon.conf:ro"
      - "/mnt/comp/avahi/services:/etc/avahi/services:ro"
  tags:
    - docker
    - avahi

